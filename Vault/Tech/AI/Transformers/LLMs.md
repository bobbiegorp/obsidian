Large language models based on the Transformer architecture. Huge models with billions of weights trained on enormous datasets. There are a handful of providers that train these huge models and make them available. Training these models is very costly so this is usually not something that an AI-using average company does itself. Instead they rely on the models - also called Foundation models - from the providers and build their applications around those, including guardrails and specific instructions for those applications.